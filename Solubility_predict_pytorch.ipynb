{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solubility_predict_pytorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhdUKqcPxzrI",
        "outputId": "ad9a73dd-6de9-485c-af14-de93d6b7f7b4"
      },
      "source": [
        "!pip install pysmiles "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysmiles\n",
            "  Downloading pysmiles-1.0.1.tar.gz (34 kB)\n",
            "Collecting pbr\n",
            "  Using cached pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "Requirement already satisfied: networkx~=2.0 in /usr/local/lib/python3.7/dist-packages (from pysmiles) (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx~=2.0->pysmiles) (4.4.2)\n",
            "Building wheels for collected packages: pysmiles\n",
            "  Building wheel for pysmiles (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysmiles: filename=pysmiles-1.0.1-py2.py3-none-any.whl size=22028 sha256=f6800f3ff2e89723028e7c258df1e731bec0e89c80fce622d728cc8cc3116718\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/f0/ca/dae2e932684a6e26824d29cf5b6dadea7320e6fed036942972\n",
            "Successfully built pysmiles\n",
            "Installing collected packages: pbr, pysmiles\n",
            "Successfully installed pbr-5.6.0 pysmiles-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7NqhJKrx_EK",
        "outputId": "bb382472-8509-46be-84ec-cc52c604c87b"
      },
      "source": [
        "!pip install torch_geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.5.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch_geometric) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch_geometric) (57.2.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388142 sha256=de290a3fe76d4fa1f659428f4248418086eff3bb77e5840db349bb00b1b09512\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUFNJo2NyMey",
        "outputId": "8147a386-18f6-47b0-d45f-f8e0c52b605a"
      },
      "source": [
        "!pip install torch_sparse "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.11.tar.gz (40 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 30 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch_sparse) (1.19.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl size=444203 sha256=b406ec9b02c1520ddfe862080ea7c6d2a516370b8a3ff4d71b29e43116fc7177\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/96/50/6d96633dcb6fa6afd1b210a4cdeb1fa30a400c352b88732a1f\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtvE4YVZ0nIi",
        "outputId": "2d976a58-f22a-4014-ff2e-e97561ff76b3"
      },
      "source": [
        "!pip install torch_scatter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_scatter\n",
            "  Downloading torch_scatter-2.0.8.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl size=281098 sha256=c231739d83a9feb90fe32d57dbd9796cd3bebe3aca8d24236fbdafbaf9128e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/e4/4e/2bcc6de6a801960aedbca43f7106d268f766c3f9f8ab49b3a5\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtzm3qh3xt1V"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from pysmiles import read_smiles\n",
        "import pandas as pd\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, GCNConv\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, degree\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "logging.getLogger('pysmiles').setLevel(logging.CRITICAL)  # Anything higher than warning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZG-wJ5yJ4H",
        "outputId": "dfd69650-dd48-41f7-efc6-54ddc730b005"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/curated-solubility-dataset.csv') #read dataset (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n",
        "X_smiles = list(df['SMILES']) #get smiles strings from file\n",
        "Y = np.asarray(df['Solubility']) #get solubility values from file\n",
        "\n",
        "elements = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',    #list of all elements in the dataset\n",
        "            'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce', \n",
        "            'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al', \n",
        "            'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn', \n",
        "            'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd', \n",
        "            'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C']\n",
        "\n",
        "#convert element to a one-hot vector of dimension len(elements)\n",
        "def element_to_onehot(element):\n",
        "    out = []\n",
        "    for i in range(0, len(element)):\n",
        "        v = np.zeros(len(elements))\n",
        "        v[elements.index(element[i])] = 1.0\n",
        "        out.append(v)\n",
        "    return np.asarray(out)\n",
        "\n",
        "#convert solubility value to one-hot class vector\n",
        "def val_to_class(val):\n",
        "    if val < -3.65: #insoluble\n",
        "        return [1, 0, 0]\n",
        "    elif val < -1.69: #slightly soluble\n",
        "        return [0, 1, 0]\n",
        "    else: #soluble\n",
        "        return [0, 0, 1]\n",
        "\n",
        "#process SMILES strings into graphs\n",
        "nodes = []\n",
        "edge_index = []\n",
        "for smiles in tqdm(X_smiles):\n",
        "    try:\n",
        "        G = read_smiles(smiles, explicit_hydrogen=True)\n",
        "        feature = element_to_onehot(np.asarray(G.nodes(data='element'))[:, 1])\n",
        "        edges = np.asarray(G.edges)\n",
        "        index = np.asarray([edges[:,0], edges[:,1]]) #reshape indices into shape [2, -1]\n",
        "        nodes.append(feature)\n",
        "        edge_index.append(index)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9982/9982 [00:14<00:00, 670.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMPS74QP4CU3",
        "outputId": "20d15362-e899-47ad-f5aa-7e81f6bd08e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVJljSIl8YSi",
        "outputId": "f8365f09-a6e5-4de6-b88b-e512729e3d3d"
      },
      "source": [
        "#Generate Data objects\n",
        "data = list()\n",
        "\n",
        "#process graphs into torch_geometric Data objects\n",
        "for i in tqdm(range(0, len(nodes))):\n",
        "    x = torch.tensor(nodes[i], dtype=torch.float) #convert node features into torch tensor\n",
        "    edges = torch.tensor(edge_index[i], dtype=torch.long) #convert edge index into torch tensor\n",
        "    y = torch.tensor([val_to_class(Y[i])], dtype=torch.float) #change shape of label and convert to tensor\n",
        "    data.append(Data(x=x,edge_index=edges, y=y)) #add the Data object to the list of data\n",
        "random.shuffle(data)\n",
        "train = data[:int(len(data)*0.8)] #train set\n",
        "test = data[int(len(data)*0.8):] #val set\n",
        "train = data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9946/9946 [00:00<00:00, 26226.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzdmQID8gpO"
      },
      "source": [
        "#define the message passing network\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(61, 32)\n",
        "        self.conv2 = GCNConv(32, 32)\n",
        "        self.conv3 = GCNConv(32, 32)\n",
        "        self.conv4 = GCNConv(32, 32)\n",
        "        self.lin1 = Linear(32, 16)\n",
        "        self.lin2 = Linear(16, 3)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index= data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "        \n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "        \n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = torch.sum(x, dim=0)\n",
        "        x = self.lin1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.lin2(x)\n",
        "        \n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5_KNbEK8lq5"
      },
      "source": [
        "#set up device and create model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n",
        "model = Net().to(device) #create network and send to the device memory\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n",
        "CSE = CrossEntropyLoss() #define loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl2ea9Sq8nVe",
        "outputId": "0a39556e-aa83-4b8d-8695-3b42a9a4fe3d"
      },
      "source": [
        "#train model\n",
        "model.train() #set model to training mode\n",
        "for epoch in range(2): #run for epochs of training\n",
        "    sum_loss = 0 #used to compute average loss in an epoch\n",
        "    num_correct = 0\n",
        "    random.shuffle(train) #shuffle the training data each epoch\n",
        "    for d in tqdm(train): #go over each training point\n",
        "        data = d.to(device) #send data to device\n",
        "        optimizer.zero_grad() #zero gradients\n",
        "        out = model(data) #evaluate data point\n",
        "        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n",
        "            num_correct += 1\n",
        "        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n",
        "        sum_loss += float(loss) #add loss value to aggregate loss\n",
        "        loss.backward() #compute gradients\n",
        "        optimizer.step() #apply optimization\n",
        "    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9946/9946 [00:42<00:00, 233.56it/s]\n",
            "  0%|          | 25/9946 [00:00<00:39, 249.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000, Average loss: 1.07927, Accuracy: 0.39433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9946/9946 [00:43<00:00, 226.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, Average loss: 1.06912, Accuracy: 0.41333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "zQa7w_K89JSQ",
        "outputId": "43e7234e-93df-47d2-b07e-0990045bd121"
      },
      "source": [
        "#test the model and display a histogram of the outputs\n",
        "num_correct = 0\n",
        "model.eval()\n",
        "predictions = list()\n",
        "for t in tqdm(test):\n",
        "    d = t.to(device)\n",
        "    out = model(d)\n",
        "    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n",
        "            num_correct += 1\n",
        "    predictions.append(torch.argmax(out).item())\n",
        "    \n",
        "print(\"Test accuracy: \" + str(num_correct/len(test)))\n",
        "plt.hist(predictions, bins=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1990/1990 [00:04<00:00, 434.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.43417085427135677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([520., 951., 519.]),\n",
              " array([0.        , 0.66666667, 1.33333333, 2.        ]),\n",
              " <a list of 3 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLL6VWpm9Shu"
      },
      "source": [
        "#test SMILES string\n",
        "def evaluate_smiles(smiles_string):\n",
        "    classes = ['insoluble', 'slightly soluble', 'soluble']\n",
        "    G = read_smiles(smiles_string, explicit_hydrogen=True) #decode smiles string\n",
        "    feature = element_to_onehot(np.asarray(G.nodes(data='element'))[:, 1]) #convert element to one-hot vector\n",
        "    edges = np.asarray(G.edges) #get edge array\n",
        "    index = np.asarray([edges[:,0], edges[:,1]]) #reformat edge array to torch geometric suitable format\n",
        "    d = Data(x=torch.tensor(feature, dtype=torch.float),edge_index=torch.tensor(index, dtype=torch.long)) #create torch gemoetry Data object\n",
        "    data = d.to(device) #send data to device memory\n",
        "    model.eval() #set model to evaluate mode\n",
        "    print(classes[torch.argmax(torch.softmax(model(data), dim=0)).item()]) #evaluate the test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGnVKDWW9UfQ",
        "outputId": "08279157-085a-40a2-fba8-83fb1c724b4d"
      },
      "source": [
        "evaluate_smiles('C1:C:C:C2:C(:C:1):C:C:C1:C:2:C:C:C2:C3:C:C:C:C:C:3:C:C:C:2:1') #test out the model on Vitamin C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insoluble\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}